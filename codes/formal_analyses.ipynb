{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841a109-f7e7-4fdf-96e9-92ca63f6855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75978763-4d7f-412d-a7b1-11f1cd690807",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = ['', '']\n",
    "cystic_artery_velocity_negative_cases_path = ''\n",
    "\n",
    "# \"Easy negatives\" are patients who were determined not to have acute cholecystitis based on clinical grounds, and did not undergo surgery\n",
    "include_easy_negatives = True\n",
    "\n",
    "# \"Hard negatives\" are patients who underwent cholecystectomy but pathology confirmed no acute cholecystitis.\n",
    "include_hard_negatives = False\n",
    "include_chronic_cholecystitis = False\n",
    "\n",
    "# value to use for 'equivocal' categorical feature interpretation\n",
    "# None: equivocal cases are excluded\n",
    "# 1: equivocal feature interpretations are treated as 'present'\n",
    "# 0: equivocal feature interpretations are treated as 'absent'\n",
    "surrogate_for_equivocal = None\n",
    "\n",
    "demographics_paths = [('', ''),\n",
    "                       ('', '')]\n",
    "\n",
    "# continuous variables\n",
    "parameter_columns = [\n",
    "    'API_US_cystic_artery_velocity_max(cm/s)',\n",
    "    'API_US_hepatic_artery_velocity_max(cm/s)',\n",
    "    'API_US_GB_wall_thickness_max (mm)',\n",
    "    'API_US_gallbladder_size(cm)_dimension1',\n",
    "    'API_US_gallbladder_size(cm)_dimension2',\n",
    "    'gallbladder_area'\n",
    "                    ]\n",
    "\n",
    "# categorical variables\n",
    "categorical_parameter_columns = [\n",
    "    'API_US_gallstone_cleaned',\n",
    "    'API_US_gallbladder_sludge_cleaned',\n",
    "    'API_US_GB_wall_thick (yes/no)_cleaned',\n",
    "    'API_US_pericholecystic_fluid_cleaned',\n",
    "    'API_US_sonographic_murphys_cleaned',\n",
    "                                ]\n",
    "                                 \n",
    "outcome_columns = ['patho_acute_cholecystitis']\n",
    "\n",
    "demographics_columns = [\n",
    "    'Age_rad',\n",
    "    'Gender',\n",
    "    'Race',\n",
    "    'Ethnicity',\n",
    "    'Recent BMI'\n",
    "]\n",
    "\n",
    "set_prevalence = 0.5  # None if use the prevalence in the dataset\n",
    "\n",
    "export_dir = ''\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "if include_chronic_cholecystitis:\n",
    "    map_col_to_selected_thresholds = {\n",
    "        'API_US_cystic_artery_velocity_max(cm/s)': [42.6, 24.6, 34.0],\n",
    "        'API_US_hepatic_artery_velocity_max(cm/s)': [95.5],\n",
    "        'API_US_GB_wall_thickness_max (mm)': [4.0],\n",
    "        'API_US_gallbladder_size(cm)_dimension1': [8.4],\n",
    "        'API_US_gallbladder_size(cm)_dimension2': [3.8, 2.7, 2.2],\n",
    "        'gallbladder_area': [30.36],\n",
    "    }\n",
    "\n",
    "if include_easy_negatives:\n",
    "    map_col_to_selected_thresholds = {\n",
    "        'API_US_cystic_artery_velocity_max(cm/s)': [42.6, 24.6, 34.0],\n",
    "        'API_US_hepatic_artery_velocity_max(cm/s)': [95.5],\n",
    "        'API_US_GB_wall_thickness_max (mm)': [4.0],\n",
    "        'API_US_gallbladder_size(cm)_dimension1': [8.4],\n",
    "        'API_US_gallbladder_size(cm)_dimension2': [3.8, 2.7, 2.2],\n",
    "        'gallbladder_area': [30.36, 39.60, 17.36],\n",
    "    }\n",
    "\n",
    "map_col_to_units = {\n",
    "    'API_US_cystic_artery_velocity_max(cm/s)': 'cm/s',\n",
    "    'API_US_hepatic_artery_velocity_max(cm/s)': 'cm/s',\n",
    "    'API_US_GB_wall_thickness_max (mm)': 'mm',\n",
    "    'API_US_gallbladder_size(cm)_dimension1': 'cm',\n",
    "    'API_US_gallbladder_size(cm)_dimension2': 'cm',\n",
    "    'gallbladder_area': 'cm\\u00B2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6812c08-0b89-4fd1-b5a9-20e97f769331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_add_add_source(path):\n",
    "    df = pd.read_excel(path)\n",
    "    df['source'] = path\n",
    "    return df\n",
    "\n",
    "##############################################\n",
    "\n",
    "df = pd.concat([read_excel_add_add_source(path) for path in dataset_paths], \n",
    "               axis=0, \n",
    "               ignore_index=True)\n",
    "print(df.shape)\n",
    "\n",
    "df.loc[(df['patho_acute_cholecystitis']=='yes') | (df['cholecystostomy_acute_cholecystitis']=='yes'), 'comparison_group'] = 'positives'\n",
    "df.loc[(df['patho_acute_cholecystitis']=='no') | (df['cholecystostomy_acute_cholecystitis']=='no'), 'comparison_group'] = 'hard negatives'\n",
    "\n",
    "if not include_hard_negatives:\n",
    "    df = df.loc[(df['patho_acute_cholecystitis']=='yes') | (df['cholecystostomy_acute_cholecystitis']=='yes')].reset_index(drop=True)\n",
    "elif include_hard_negatives:\n",
    "    if include_chronic_cholecystitis:\n",
    "        df = df.loc[(df['patho_acute_cholecystitis']=='yes') | \\\n",
    "                    ((df['patho_acute_cholecystitis']=='no') & (df['patho_chronic_cholecystitis']=='yes'))].reset_index(drop=True)\n",
    "\n",
    "if (cystic_artery_velocity_negative_cases_path is not None) and include_easy_negatives:\n",
    "    cystic_df = read_excel_add_add_source(cystic_artery_velocity_negative_cases_path)\n",
    "\n",
    "    cystic_df = cystic_df.loc[(cystic_df['US_acute_cholecystitis'].isin(['no','dirty negative'])) & \\\n",
    "                            (cystic_df['priority']==7)].reset_index(drop=True)\n",
    "    \n",
    "    # set these columns to 'no', so that the cases are included as negative controls\n",
    "    cystic_df['patho_acute_cholecystitis'] = 'no'\n",
    "    cystic_df['patho_gangrenous'] = 'no'\n",
    "    cystic_df['cholecystostomy_acute_cholecystitis'] = 'no'\n",
    "\n",
    "    cystic_df['comparison_group'] = 'easy negatives'\n",
    "\n",
    "    df = pd.concat([df, cystic_df],\n",
    "                  axis=0,\n",
    "                  ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5caa0",
   "metadata": {},
   "source": [
    "# add demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_demographics(demographics_path, codebook_path):\n",
    "    demographics = pd.read_csv(demographics_path)\n",
    "    codebook = pd.read_csv(codebook_path)\n",
    "    codebook = codebook.rename(columns={'Patient id':'Patient Id'})\n",
    "    demographics = demographics[['Patient Id',\n",
    "                                 'Gender',\n",
    "                                 'Race',\n",
    "                                 'Ethnicity',\n",
    "                                 'Recent Height cm',\n",
    "                                 'Recent Weight kg',\n",
    "                                 'Recent BMI']].merge(codebook[['Patient Id','MRN']], \n",
    "                                                    on='Patient Id', \n",
    "                                                    how='inner')\n",
    "    return demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "demographics_df = pd.concat([read_demographics(demographics_path, codebook_path) for demographics_path, codebook_path in demographics_paths],\n",
    "                            axis=0,\n",
    "                            ignore_index=True)\n",
    "\n",
    "demographics_df = demographics_df.drop_duplicates(subset='MRN').reset_index(drop=True)\n",
    "\n",
    "df = df.merge(demographics_df,\n",
    "                on='MRN',\n",
    "                how='left').reset_index(drop=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use gallbladder sizes from cases where only one dimension is available\n",
    "\n",
    "dimension_columns = ['API_US_gallbladder_size(cm)_dimension1',\n",
    "                    'API_US_gallbladder_size(cm)_dimension2',\n",
    "                    'API_US_gallbladder_size(cm)_dimension3']\n",
    "\n",
    "indices_to_delete = df['API_US_gallbladder_size(cm)_dimension1'].isna() | df['API_US_gallbladder_size(cm)_dimension2'].isna()\n",
    "for col in dimension_columns:\n",
    "    df.loc[indices_to_delete, col] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33ad0e",
   "metadata": {},
   "source": [
    "# calculate gallbladder area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60606512",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_indices = df['API_US_gallbladder_size(cm)_dimension1'].notna() & df['API_US_gallbladder_size(cm)_dimension2'].notna()\n",
    "df.loc[available_indices, 'gallbladder_area'] = df.loc[available_indices]['API_US_gallbladder_size(cm)_dimension1'] * df.loc[available_indices]['API_US_gallbladder_size(cm)_dimension2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f3f5e",
   "metadata": {},
   "source": [
    "# Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99beb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptives(df, outcome_col):\n",
    "    print(outcome_col)\n",
    "    sub_df = df.loc[df[outcome_col].notna()].copy().reset_index(drop=True)\n",
    "    for group in ['positives', 'hard negatives', 'easy negatives']:\n",
    "        print(group)\n",
    "        group_df = sub_df.loc[sub_df['comparison_group']==group].copy().reset_index(drop=True)\n",
    "        print('number of cases:', group_df.shape[0])\n",
    "        for col in demographics_columns:\n",
    "            print(group_df[col].value_counts(dropna=False))\n",
    "            print(group_df[col].value_counts(normalize=True, dropna=False))\n",
    "            print(group_df[col].describe())\n",
    "            print('\\n')\n",
    "        for col in parameter_columns:\n",
    "            print(group_df[col].describe())\n",
    "            print('\\n')\n",
    "        for col in categorical_parameter_columns:\n",
    "            print(group_df[col].value_counts(dropna=False))\n",
    "            print(group_df[col].value_counts(normalize=True, dropna=False))\n",
    "            print('\\n')\n",
    "        for col in outcome_columns:\n",
    "            print(group_df[col].value_counts(dropna=False))\n",
    "            print(group_df[col].value_counts(normalize=True, dropna=False))\n",
    "            print('\\n')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome_col in outcome_columns:\n",
    "    descriptives(df, outcome_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafed1e",
   "metadata": {},
   "source": [
    "# Begin analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa6ad5-9764-44c5-9060-f186de22d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['patho_acute_cholecystitis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b298046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['patho_acute_cholecystitis']=='no']['patho_chronic_cholecystitis'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3aa244-fbf8-45a6-83c4-ff034e6fd1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~(df['priority'].isin([4,6])), 'final_Dx_acute_cholecystitis'] = df.loc[~(df['priority'].isin([4,6]))]['patho_acute_cholecystitis']\n",
    "df.loc[df['priority'].isin([4,6]), 'final_Dx_acute_cholecystitis'] = df.loc[df['priority'].isin([4,6])]['cholecystostomy_acute_cholecystitis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf2885-113f-4ecd-8f4f-5f7d8795e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_Dx_acute_cholecystitis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7c70e-2345-4fd9-8aa3-22122884de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx in df.index:\n",
    "    acute = df.loc[row_idx, 'patho_acute_cholecystitis']\n",
    "    if acute == 'yes':\n",
    "        gangrenous = df.loc[row_idx, 'patho_gangrenous']\n",
    "        if gangrenous == 'yes':\n",
    "            df.loc[row_idx, 'gangrenous_vs_nongangrenous_acute_cholecystitis'] = 'yes'\n",
    "            df.loc[row_idx, 'gangrenous_vs_nongangrenous_acute_cholecystitis (assume cholecystostomy cases are gangrenous)'] = 'yes'\n",
    "        elif gangrenous == 'no':\n",
    "            df.loc[row_idx, 'gangrenous_vs_nongangrenous_acute_cholecystitis'] = 'no'\n",
    "            df.loc[row_idx, 'gangrenous_vs_nongangrenous_acute_cholecystitis (assume cholecystostomy cases are gangrenous)'] = 'no'\n",
    "\n",
    "    if df.loc[row_idx, 'cholecystostomy_acute_cholecystitis'] == 'yes':\n",
    "        df.loc[row_idx, 'gangrenous_vs_nongangrenous_acute_cholecystitis (assume cholecystostomy cases are gangrenous)'] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa663b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter_col in parameter_columns + categorical_parameter_columns:\n",
    "    print('\\n')\n",
    "    print(parameter_col)\n",
    "    for outcome_col in outcome_columns:\n",
    "        print(df.loc[df[parameter_col].notna()][outcome_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173b792-6534-4c49-81a0-dd42cdf2735d",
   "metadata": {},
   "source": [
    "# Diagnostic performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ba448-74d5-4584-b988-ef2ddb1a3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_diagnostic_performance(df, parameter_col, outcome_col):\n",
    "\n",
    "    sub_df = df.loc[df[parameter_col].notna() & \\\n",
    "                    df[outcome_col].notna()].copy().reset_index(drop=True)\n",
    "    print(sub_df.shape)\n",
    "\n",
    "    if sub_df.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    print(sub_df[outcome_col].value_counts())\n",
    "\n",
    "    if set_prevalence is None:\n",
    "        prevalence = (sub_df[outcome_col]=='yes').sum() / sub_df.shape[0]\n",
    "    else:\n",
    "        prevalence = set_prevalence\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(y_true = sub_df[outcome_col], \n",
    "                                     y_score = sub_df[parameter_col],\n",
    "                                     pos_label = 'yes')\n",
    "    \n",
    "    auroc = roc_auc_score(y_true = sub_df[outcome_col]=='yes', \n",
    "                         y_score = sub_df[parameter_col])\n",
    "\n",
    "    map_colname = {\n",
    "        'API_US_cystic_artery_velocity_max(cm/s)': 'Cystic artery velocity',\n",
    "        'API_US_hepatic_artery_velocity_max(cm/s)': 'Hepatic artery velocity',\n",
    "        'API_US_GB_wall_thickness_max (mm)': 'Gallbladder wall thickness',\n",
    "        'API_US_gallbladder_size(cm)_dimension1': 'Gallbladder longitudinal dimension',\n",
    "        'API_US_gallbladder_size(cm)_dimension2': 'Gallbladder transverse dimension',\n",
    "        'gallbladder_area': 'Gallbladder longitudinal * transverse'\n",
    "    }\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(fpr, tpr, label = f'AUROC = {auroc:.2f}')\n",
    "    plt.xlabel('1 - specificity')\n",
    "    plt.ylabel('sensitivity')\n",
    "    plt.title(map_colname[parameter_col])\n",
    "    plt.legend()\n",
    "\n",
    "    # annotate thresholds on the plot\n",
    "    for x,y,velocity in zip(fpr,tpr,thresholds):\n",
    "        if round(velocity,2) in map_col_to_selected_thresholds[parameter_col]:\n",
    "            ax.annotate('{0:.1f} {1}'.format(round(velocity,1), map_col_to_units[parameter_col]), \n",
    "                        xy=(x+0.02,y-0.04),\n",
    "                        textcoords='offset points')\n",
    "            ax.scatter(x, y, color='green')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    # calculate other metrics\n",
    "    sens = tpr\n",
    "    spec = 1 - fpr\n",
    "    ppv = (sens*prevalence) / ((sens*prevalence) + ((1-spec)*(1-prevalence)))\n",
    "    npv = (spec*(1-prevalence)) / (((1-sens)*prevalence)+(spec*(1-prevalence)))\n",
    "    pos_lr = sens / (1-spec)\n",
    "    neg_lr = (1-sens) / spec\n",
    "    \n",
    "    # write results to dataframe\n",
    "    out_df = pd.DataFrame({\n",
    "        'prevalence': [prevalence]*len(thresholds),\n",
    "        'threshold': thresholds,\n",
    "        'sensitivity': sens,\n",
    "        'specificity': spec,\n",
    "        'PPV': ppv,\n",
    "        'NPV': npv,\n",
    "        'positive_likelihood_ratio': pos_lr,\n",
    "        'negative_likelihood_ratio': neg_lr,\n",
    "        'AUROC': [auroc]*len(thresholds)\n",
    "    })\n",
    "\n",
    "    out_df.to_excel(export_dir + parameter_col.replace('/','per') + ' prevalence_{0:.2f}'.format(prevalence) + '.xlsx',\n",
    "                   index=False)\n",
    "\n",
    "    # plot sens, spec, PPV, NPV for each threshold\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(thresholds, sens, label = 'sensitivity')\n",
    "    ax.plot(thresholds, spec, label = 'specificity')\n",
    "    ax.plot(thresholds, ppv, label = 'PPV')\n",
    "    ax.plot(thresholds, npv, label = 'NPV')\n",
    "    plt.xlabel('thresholds')\n",
    "    plt.ylabel('metrics')\n",
    "    plt.title(parameter_col + '\\n' + outcome_col + '\\n' + 'prevalence {0:.2f}'.format(prevalence))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot LR+ and LR- for each threshold\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(thresholds, pos_lr, label = 'LR+')\n",
    "    ax.plot(thresholds, neg_lr, label = 'LR-')\n",
    "    plt.xlabel('thresholds')\n",
    "    plt.ylabel('metrics')\n",
    "    plt.title(parameter_col + '\\n' + outcome_col + '\\n' + 'prevalence {0:.2f}'.format(prevalence))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('N:', sub_df.shape[0])\n",
    "    print('pretest probability:', prevalence)\n",
    "    print('AUROC:', auroc)\n",
    "\n",
    "    # find performance at 90% spec\n",
    "    spec90_df = out_df.loc[out_df['specificity']>=0.9].reset_index(drop=True)\n",
    "    spec90_df = spec90_df.sort_values(by=['sensitivity'], ascending=False, ignore_index=True)\n",
    "    spec90_series = spec90_df.iloc[0,:]\n",
    "    print('\\nperformance at 0.9 specificity')\n",
    "    print(spec90_series)\n",
    "\n",
    "    # find performance at 90% sens\n",
    "    sens90_df = out_df.loc[out_df['sensitivity']>=0.9].reset_index(drop=True)\n",
    "    sens90_df = sens90_df.sort_values(by=['specificity'], ascending=False, ignore_index=True)\n",
    "    sens90_series = sens90_df.iloc[0,:]\n",
    "    print('\\nperformance at 0.9 sensitivity')\n",
    "    print(sens90_series)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f07b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_diagnostic_performance_categorical(df, parameter_col, outcome_col):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    df_copy.loc[:,parameter_col] = df_copy[parameter_col].map({'yes': 1,\n",
    "                                                    'no': 0,\n",
    "                                                    'equivocal': surrogate_for_equivocal})\n",
    "    df_copy.loc[:,outcome_col] = df_copy[outcome_col].map({'yes': 1,\n",
    "                                                'no': 0})\n",
    "\n",
    "    sub_df = df_copy.loc[df_copy[parameter_col].notna() & \\\n",
    "                        df_copy[outcome_col].notna()].copy().reset_index(drop=True)\n",
    "    print(sub_df.shape)\n",
    "\n",
    "    if sub_df.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    print(sub_df[outcome_col].value_counts())\n",
    "\n",
    "    if set_prevalence is None:\n",
    "        prevalence = (sub_df[outcome_col]==1).sum() / sub_df.shape[0]\n",
    "    else:\n",
    "        prevalence = set_prevalence\n",
    "\n",
    "    sens = recall_score(sub_df[outcome_col].astype(int),\n",
    "                        sub_df[parameter_col].astype(int),\n",
    "                        pos_label = 1)\n",
    "    spec = recall_score(sub_df[outcome_col].astype(int),\n",
    "                        sub_df[parameter_col].astype(int),\n",
    "                        pos_label = 0)\n",
    "\n",
    "    # calculate other metrics\n",
    "    ppv = (sens*prevalence) / ((sens*prevalence) + ((1-spec)*(1-prevalence)))\n",
    "    npv = (spec*(1-prevalence)) / (((1-sens)*prevalence)+(spec*(1-prevalence)))\n",
    "    pos_lr = sens / (1-spec)\n",
    "    neg_lr = (1-sens) / spec\n",
    "\n",
    "    print('N:', sub_df.shape[0])\n",
    "    print('pretest probability:', prevalence)\n",
    "    print('sensitivity:', sens)\n",
    "    print('specificity:', spec)\n",
    "    print('LR+:', pos_lr)\n",
    "    print('LR-:', neg_lr)\n",
    "    print('PPV:', ppv)\n",
    "    print('NPV:', npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap\n",
    "def evaluate_diagnostic_performance_categorical_bootstrap(df, parameter_col, outcome_col):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    df_copy.loc[:,parameter_col] = df_copy[parameter_col].map({'yes': 1,\n",
    "                                                    'no': 0,\n",
    "                                                    'equivocal': surrogate_for_equivocal})\n",
    "    df_copy.loc[:,outcome_col] = df_copy[outcome_col].map({'yes': 1,\n",
    "                                                'no': 0})\n",
    "\n",
    "    sub_df = df_copy.loc[df_copy[parameter_col].notna() & \\\n",
    "                        df_copy[outcome_col].notna()].copy().reset_index(drop=True)\n",
    "\n",
    "    if sub_df.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    if set_prevalence is None:\n",
    "        prevalence = (sub_df[outcome_col]==1).sum() / sub_df.shape[0]\n",
    "    else:\n",
    "        prevalence = set_prevalence\n",
    "\n",
    "    sens = recall_score(sub_df[outcome_col].astype(int),\n",
    "                        sub_df[parameter_col].astype(int),\n",
    "                        pos_label = 1)\n",
    "    spec = recall_score(sub_df[outcome_col].astype(int),\n",
    "                        sub_df[parameter_col].astype(int),\n",
    "                        pos_label = 0)\n",
    "\n",
    "    # calculate other metrics\n",
    "    ppv = (sens*prevalence) / ((sens*prevalence) + ((1-spec)*(1-prevalence)))\n",
    "    npv = (spec*(1-prevalence)) / (((1-sens)*prevalence)+(spec*(1-prevalence)))\n",
    "    pos_lr = sens / (1-spec)\n",
    "    neg_lr = (1-sens) / spec\n",
    "\n",
    "    # bootstrap\n",
    "    n_bootstrap = 10000\n",
    "    sens_bootstrap = np.zeros(n_bootstrap)\n",
    "    spec_bootstrap = np.zeros(n_bootstrap)\n",
    "    ppv_bootstrap = np.zeros(n_bootstrap)\n",
    "    npv_bootstrap = np.zeros(n_bootstrap)\n",
    "    pos_lr_bootstrap = np.zeros(n_bootstrap)\n",
    "    neg_lr_bootstrap = np.zeros(n_bootstrap)\n",
    "\n",
    "    for i in tqdm(range(n_bootstrap)):\n",
    "        indices = np.random.choice(sub_df.index, size=sub_df.shape[0], replace=True)\n",
    "        sens_bootstrap[i] = recall_score(sub_df.loc[indices][outcome_col].astype(int),\n",
    "                                         sub_df.loc[indices][parameter_col].astype(int),\n",
    "                                         pos_label = 1)\n",
    "        spec_bootstrap[i] = recall_score(sub_df.loc[indices][outcome_col].astype(int),\n",
    "                                         sub_df.loc[indices][parameter_col].astype(int),\n",
    "                                         pos_label = 0)\n",
    "        ppv_bootstrap[i] = (sens_bootstrap[i]*prevalence) / ((sens_bootstrap[i]*prevalence) + ((1-spec_bootstrap[i])*(1-prevalence)))\n",
    "        npv_bootstrap[i] = (spec_bootstrap[i]*(1-prevalence)) / (((1-sens_bootstrap[i])*prevalence)+(spec_bootstrap[i]*(1-prevalence)))\n",
    "        pos_lr_bootstrap[i] = sens_bootstrap[i] / (1-spec_bootstrap[i])\n",
    "        neg_lr_bootstrap[i] = (1-sens_bootstrap[i]) / spec_bootstrap[i]\n",
    "\n",
    "    # print bootstrap results\n",
    "    print('sensitivity:', round(sens*100,1), '95% CI:', tuple(np.round(np.percentile(sens_bootstrap, [2.5, 97.5])*100,1)))\n",
    "    print('specificity:', round(spec*100,1), '95% CI:', tuple(np.round(np.percentile(spec_bootstrap, [2.5, 97.5])*100,1)))\n",
    "    print('LR+:', round(pos_lr,2), '95% CI:', tuple(np.round(np.percentile(pos_lr_bootstrap, [2.5, 97.5]),2)))\n",
    "    print('LR-:', round(neg_lr,2), '95% CI:', tuple(np.round(np.percentile(neg_lr_bootstrap, [2.5, 97.5]),2)))\n",
    "    print('PPV:', round(ppv*100,1), '95% CI:', tuple(np.round(np.percentile(ppv_bootstrap, [2.5, 97.5])*100,1)))\n",
    "    print('NPV:', round(npv*100,1), '95% CI:', tuple(np.round(np.percentile(npv_bootstrap, [2.5, 97.5])*100,1)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216d630-50c7-4a26-a1af-019e0f4fb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# continuous variables\n",
    "for parameter_col in parameter_columns:\n",
    "    print('\\n')\n",
    "    print(parameter_col)\n",
    "    for outcome_col in outcome_columns:\n",
    "        print(outcome_col)\n",
    "        evaluate_diagnostic_performance(df, parameter_col, outcome_col)\n",
    "\n",
    "# categorical variables\n",
    "for parameter_col in categorical_parameter_columns:\n",
    "    print('\\n')\n",
    "    print(parameter_col)\n",
    "    for outcome_col in outcome_columns:\n",
    "        print(outcome_col)\n",
    "        evaluate_diagnostic_performance_categorical(df, parameter_col, outcome_col)\n",
    "        evaluate_diagnostic_performance_categorical_bootstrap(df, parameter_col, outcome_col)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31dd87",
   "metadata": {},
   "source": [
    "# Bootstrap for continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_diagnostic_performance(sub_df, parameter_col, outcome_col):\n",
    "\n",
    "    if set_prevalence is None:\n",
    "        prevalence = (sub_df[outcome_col]=='yes').sum() / sub_df.shape[0]\n",
    "    else:\n",
    "        prevalence = set_prevalence\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(y_true = sub_df[outcome_col], \n",
    "                                     y_score = sub_df[parameter_col],\n",
    "                                     pos_label = 'yes')\n",
    "    \n",
    "    auroc = roc_auc_score(y_true = sub_df[outcome_col]=='yes', \n",
    "                         y_score = sub_df[parameter_col])\n",
    "\n",
    "    # calculate other metrics\n",
    "    sens = tpr\n",
    "    spec = 1 - fpr\n",
    "    ppv = (sens*prevalence) / ((sens*prevalence) + ((1-spec)*(1-prevalence)))\n",
    "    npv = (spec*(1-prevalence)) / (((1-sens)*prevalence)+(spec*(1-prevalence)))\n",
    "    pos_lr = sens / (1-spec)\n",
    "    neg_lr = (1-sens) / spec\n",
    "    \n",
    "    # write results to dataframe\n",
    "    out_df = pd.DataFrame({\n",
    "        'prevalence': [prevalence]*len(thresholds),\n",
    "        'threshold': thresholds,\n",
    "        'sensitivity': sens,\n",
    "        'specificity': spec,\n",
    "        'PPV': ppv,\n",
    "        'NPV': npv,\n",
    "        'positive_likelihood_ratio': pos_lr,\n",
    "        'negative_likelihood_ratio': neg_lr,\n",
    "        'AUROC': [auroc]*len(thresholds)\n",
    "    })\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "\n",
    "for parameter_col in parameter_columns:\n",
    "    print('\\n')\n",
    "    print(parameter_col)\n",
    "    for outcome_col in outcome_columns:\n",
    "        print(outcome_col)\n",
    "        \n",
    "        # bootstrap\n",
    "        available_df = df.loc[df[parameter_col].notna() & \\\n",
    "                            df[outcome_col].notna()].copy().reset_index(drop=True)\n",
    "        print(available_df.shape)\n",
    "        if available_df.shape[0] == 0:\n",
    "            pass\n",
    "\n",
    "        results_df = pd.DataFrame({\n",
    "            'prevalence': [],\n",
    "            'threshold': [],\n",
    "            'sensitivity': [],\n",
    "            'specificity': [],\n",
    "            'PPV': [],\n",
    "            'NPV': [],\n",
    "            'positive_likelihood_ratio': [],\n",
    "            'negative_likelihood_ratio': [],\n",
    "            'AUROC': [],\n",
    "            'bootstrap_iteration': []\n",
    "        })\n",
    "\n",
    "        for i in tqdm(range(iterations)):\n",
    "            sampled_indices = np.random.choice(available_df.index, \n",
    "                                               size=available_df.shape[0],\n",
    "                                               replace=True)\n",
    "            bootstrap_df = available_df.loc[sampled_indices].copy().reset_index(drop=True)\n",
    "            out_df = bootstrap_diagnostic_performance(bootstrap_df, parameter_col, outcome_col)\n",
    "            out_df['bootstrap_iteration'] = i\n",
    "            results_df = pd.concat([results_df, out_df],\n",
    "                                  axis=0,\n",
    "                                  ignore_index=True)\n",
    "\n",
    "        # 95% CI for AUROC\n",
    "        auroc_df = results_df.drop_duplicates(subset=['bootstrap_iteration']).copy().reset_index(drop=True)\n",
    "        values = auroc_df['AUROC'].to_list()\n",
    "        lower_CI = np.quantile(values, 0.025)\n",
    "        upper_CI = np.quantile(values, 0.975)\n",
    "        print('AUROC 95% CI: ({0:.2f}, {1:.2f})'.format(lower_CI, upper_CI))\n",
    "\n",
    "        for thres in map_col_to_selected_thresholds[parameter_col]:\n",
    "            print('\\n')\n",
    "            print('threshold:', thres)\n",
    "            print('prevalence:', results_df.loc[0, 'prevalence'])\n",
    "            selected_df = results_df.loc[results_df['threshold'].round(decimals=2)==thres].copy().reset_index(drop=True)\n",
    "            print(selected_df.shape)\n",
    "            for col in ['sensitivity','specificity','positive_likelihood_ratio','negative_likelihood_ratio','PPV','NPV',]:\n",
    "                values = selected_df[col].to_list()\n",
    "                lower_CI = np.quantile(values, 0.025)\n",
    "                upper_CI = np.quantile(values, 0.975)\n",
    "                print('{0} 95% CI: ({1:.3f}, {2:.3f})'.format(col, lower_CI, upper_CI))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIRADS_indeterminate_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
